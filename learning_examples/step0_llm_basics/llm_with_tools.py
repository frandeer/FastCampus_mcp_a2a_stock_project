"""
Step 0: LLM + ë„êµ¬ í˜¸ì¶œ ì˜ˆì œ
OpenAIì˜ Function Calling ê¸°ëŠ¥ì„ ì‚¬ìš©í•´ì„œ AIê°€ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ëŠ” ë°©ë²• í•™ìŠµ

ì´ ì˜ˆì œëŠ” MCPì˜ í•µì‹¬ ì•„ì´ë””ì–´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤:
1. AIê°€ í•„ìš”ì— ë”°ë¼ ë„êµ¬ë¥¼ ì„ íƒí•˜ê³  í˜¸ì¶œ
2. ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°›ì•„ì„œ ìµœì¢… ì‘ë‹µ ìƒì„±
3. ì‚¬ìš©ìëŠ” ë³µì¡í•œ ìš”ì²­ì„ ìì—°ì–´ë¡œ í•˜ê¸°ë§Œ í•˜ë©´ ë¨

ì´ê²ƒì´ ë°”ë¡œ MCPê°€ í•˜ë ¤ëŠ” ì¼ì…ë‹ˆë‹¤!
"""

import asyncio
import json
import os
import sys
from pathlib import Path
from typing import Dict, Any, List
from openai import AsyncOpenAI

# ê³µí†µ ìœ í‹¸ë¦¬í‹° import
sys.path.append(str(Path(__file__).parent.parent))
from common_utils import get_api_key, get_setting, print_environment_status

class CalculatorTools:
    """AIê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê³„ì‚° ë„êµ¬ë“¤"""
    
    @staticmethod
    def add_numbers(a: float, b: float) -> Dict[str, Any]:
        """ë‘ ìˆ«ì ë”í•˜ê¸°"""
        result = a + b
        return {
            "operation": "addition",
            "inputs": {"a": a, "b": b},
            "result": result,
            "message": f"{a} + {b} = {result}"
        }
    
    @staticmethod
    def multiply_numbers(a: float, b: float) -> Dict[str, Any]:
        """ë‘ ìˆ«ì ê³±í•˜ê¸°"""
        result = a * b
        return {
            "operation": "multiplication", 
            "inputs": {"a": a, "b": b},
            "result": result,
            "message": f"{a} Ã— {b} = {result}"
        }
    
    @staticmethod
    def divide_numbers(a: float, b: float) -> Dict[str, Any]:
        """ë‘ ìˆ«ì ë‚˜ëˆ„ê¸°"""
        if b == 0:
            return {
                "operation": "division",
                "inputs": {"a": a, "b": b},
                "error": "0ìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                "result": None
            }
        result = a / b
        return {
            "operation": "division",
            "inputs": {"a": a, "b": b}, 
            "result": result,
            "message": f"{a} Ã· {b} = {result}"
        }
    
    @staticmethod
    def power_numbers(base: float, exponent: float) -> Dict[str, Any]:
        """ê±°ë“­ì œê³± ê³„ì‚°"""
        result = base ** exponent
        return {
            "operation": "power",
            "inputs": {"base": base, "exponent": exponent},
            "result": result,
            "message": f"{base}^{exponent} = {result}"
        }

class LLMWithTools:
    def __init__(self, api_key: str = None):
        if api_key is None:
            api_key = get_api_key('OPENAI_API_KEY', required=True)
            if not api_key:
                raise ValueError("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        
        self.client = AsyncOpenAI(api_key=api_key)
        self.model = "gpt-4o-mini"
        self.tools = CalculatorTools()
        
        # OpenAI Function Callingìš© ë„êµ¬ ì •ì˜
        self.tool_definitions = [
            {
                "type": "function",
                "function": {
                    "name": "add_numbers",
                    "description": "ë‘ ìˆ«ìë¥¼ ë”í•©ë‹ˆë‹¤",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "a": {"type": "number", "description": "ì²« ë²ˆì§¸ ìˆ«ì"},
                            "b": {"type": "number", "description": "ë‘ ë²ˆì§¸ ìˆ«ì"}
                        },
                        "required": ["a", "b"]
                    }
                }
            },
            {
                "type": "function", 
                "function": {
                    "name": "multiply_numbers",
                    "description": "ë‘ ìˆ«ìë¥¼ ê³±í•©ë‹ˆë‹¤",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "a": {"type": "number", "description": "ì²« ë²ˆì§¸ ìˆ«ì"},
                            "b": {"type": "number", "description": "ë‘ ë²ˆì§¸ ìˆ«ì"}
                        },
                        "required": ["a", "b"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "divide_numbers", 
                    "description": "ì²« ë²ˆì§¸ ìˆ«ìë¥¼ ë‘ ë²ˆì§¸ ìˆ«ìë¡œ ë‚˜ëˆ•ë‹ˆë‹¤",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "a": {"type": "number", "description": "ë‚˜ëˆ„ì–´ì§€ëŠ” ìˆ˜"},
                            "b": {"type": "number", "description": "ë‚˜ëˆ„ëŠ” ìˆ˜"}
                        },
                        "required": ["a", "b"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "power_numbers",
                    "description": "ì²« ë²ˆì§¸ ìˆ«ìë¥¼ ë‘ ë²ˆì§¸ ìˆ«ìë§Œí¼ ê±°ë“­ì œê³±í•©ë‹ˆë‹¤",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "base": {"type": "number", "description": "ë°‘"},
                            "exponent": {"type": "number", "description": "ì§€ìˆ˜"}
                        },
                        "required": ["base", "exponent"]
                    }
                }
            }
        ]
    
    async def chat_with_tools(self, user_message: str) -> str:
        """ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” AI ì±„íŒ…"""
        print(f"ğŸ‘¤ ì‚¬ìš©ì: {user_message}")
        print("ğŸ¤– AIê°€ ìƒê°í•˜ê³  í•„ìš”í•œ ë„êµ¬ë¥¼ ì„ íƒ ì¤‘...")
        
        messages = [
            {
                "role": "system", 
                "content": "ë‹¹ì‹ ì€ ìˆ˜í•™ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ê³„ì‚°ì´ í•„ìš”í•˜ë©´ ì œê³µëœ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. ê²°ê³¼ë¥¼ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
            },
            {"role": "user", "content": user_message}
        ]
        
        try:
            # ì²« ë²ˆì§¸ AI í˜¸ì¶œ (ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ ê²°ì •)
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                tools=self.tool_definitions,
                tool_choice="auto"  # AIê°€ ìë™ìœ¼ë¡œ ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ ê²°ì •
            )
            
            response_message = response.choices[0].message
            
            # ë„êµ¬ í˜¸ì¶œì´ ìˆëŠ”ì§€ í™•ì¸
            if response_message.tool_calls:
                print(f"ğŸ”§ AIê°€ {len(response_message.tool_calls)}ê°œì˜ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê¸°ë¡œ ê²°ì •í–ˆìŠµë‹ˆë‹¤")
                
                # AIì˜ ì‘ë‹µì„ ë©”ì‹œì§€ì— ì¶”ê°€
                messages.append(response_message)
                
                # ê° ë„êµ¬ í˜¸ì¶œ ì‹¤í–‰
                for tool_call in response_message.tool_calls:
                    tool_name = tool_call.function.name
                    tool_args = json.loads(tool_call.function.arguments)
                    
                    print(f"  ğŸ› ï¸  ë„êµ¬ í˜¸ì¶œ: {tool_name}({tool_args})")
                    
                    # ë„êµ¬ ì‹¤í–‰
                    if hasattr(self.tools, tool_name):
                        tool_function = getattr(self.tools, tool_name)
                        result = tool_function(**tool_args)
                        print(f"  ğŸ“Š ì‹¤í–‰ ê²°ê³¼: {result}")
                    else:
                        result = {"error": f"ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: {tool_name}"}
                    
                    # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
                    messages.append({
                        "tool_call_id": tool_call.id,
                        "role": "tool",
                        "name": tool_name,
                        "content": json.dumps(result, ensure_ascii=False)
                    })
                
                # ë„êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‘ë‹µ ìƒì„±
                print("ğŸ¤– AIê°€ ë„êµ¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì‘ë‹µì„ ìƒì„± ì¤‘...")
                final_response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=messages
                )
                
                final_answer = final_response.choices[0].message.content
                print(f"ğŸ’¬ AI ìµœì¢… ì‘ë‹µ: {final_answer}")
                return final_answer
                
            else:
                # ë„êµ¬ ì‚¬ìš© ì—†ì´ ì§ì ‘ ì‘ë‹µ
                answer = response_message.content
                print(f"ğŸ’¬ AI ì‘ë‹µ (ë„êµ¬ ì‚¬ìš© ì•ˆí•¨): {answer}")
                return answer
                
        except Exception as e:
            error_msg = f"AI í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"
            print(f"âŒ {error_msg}")
            return error_msg

async def test_llm_with_tools():
    """LLM + ë„êµ¬ í˜¸ì¶œ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ LLM + ë„êµ¬ í˜¸ì¶œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # í™˜ê²½ ì„¤ì • ìƒíƒœ ì¶œë ¥
    print_environment_status()
    
    # API í‚¤ í™•ì¸ (ì´ë¯¸ ìœ„ì—ì„œ ì¶œë ¥ë¨)
    api_key = get_api_key('OPENAI_API_KEY', required=False)
    if not api_key:
        print("\nğŸ’¡ .env íŒŒì¼ ì„¤ì • ë°©ë²•:")
        print("   1. learning_examples/.env.exampleì„ learning_examples/.envë¡œ ë³µì‚¬")
        print("   2. OPENAI_API_KEY=your-key-here ì„¤ì •")
        return
    
    # LLM + ë„êµ¬ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    llm_tools = LLMWithTools()
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
    test_cases = [
        "25 + 17ì„ ê³„ì‚°í•´ì£¼ì„¸ìš”",
        "12 ê³±í•˜ê¸° 8ì€ ì–¼ë§ˆì¸ê°€ìš”?", 
        "144ë¥¼ 12ë¡œ ë‚˜ëˆˆ ê²°ê³¼ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”",
        "2ì˜ 10ì œê³±ì€ ì–¼ë§ˆì¸ê°€ìš”?",
        "ë³µì¡í•œ ê³„ì‚°: (10 + 5) Ã— 3ì„ í•´ì£¼ì„¸ìš”",
        "ì•ˆë…•í•˜ì„¸ìš”, ë‚ ì”¨ê°€ ì–´ë–¤ê°€ìš”?",  # ë„êµ¬ ì—†ì´ ì‘ë‹µí•´ì•¼ í•˜ëŠ” ì¼€ì´ìŠ¤
    ]
    
    # ê° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    for i, test_message in enumerate(test_cases, 1):
        print(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ {i}")
        print("=" * 30)
        
        result = await llm_tools.chat_with_tools(test_message)
        
        print("âœ… ì™„ë£Œ!\n")
        
        # API í˜¸ì¶œ ì§€ì—° (.envì—ì„œ ì„¤ì • ê°€ëŠ¥)
        delay = get_setting('LEARNING_API_DELAY', 1, int)
        await asyncio.sleep(delay)
    
    print("=" * 60)
    print("ğŸ‰ LLM + ë„êµ¬ í˜¸ì¶œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print()
    print("ğŸ§  í•µì‹¬ ê°œë… ì •ë¦¬:")
    print("  1. AIê°€ ìì—°ì–´ ìš”ì²­ì„ ë¶„ì„í•´ì„œ í•„ìš”í•œ ë„êµ¬ë¥¼ ì„ íƒ")
    print("  2. ì„ íƒí•œ ë„êµ¬ë¥¼ ì ì ˆí•œ ì¸ìˆ˜ë¡œ í˜¸ì¶œ")  
    print("  3. ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ ë°›ì•„ì„œ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•˜ê²Œ ì„¤ëª…")
    print("  4. ì´ê²ƒì´ ë°”ë¡œ MCPê°€ í•˜ë ¤ëŠ” ì¼ì…ë‹ˆë‹¤!")

if __name__ == "__main__":
    asyncio.run(test_llm_with_tools())